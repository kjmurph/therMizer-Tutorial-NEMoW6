---
title: "Preparing Climate Forcings Hawaiian Longline"
author: "Phoebe Woodworth-Jefcoats & Kieran Murphy"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# House keeping

```{r}
library(tidyverse)
library(reshape2)
```


# Introduction

The aim of this tutorial is to provide an example workflow for how to incorporate temperature and phytoplankton forcings from Earth System Models into mizer models, using the therMizer package.

This script uses ISIMIP historical observed climate output for a range of phytoplankton and zooplankton products to create the background resource array that will be used by the therMizer model, in this case, the Hawaiian Longline model.

The plankton products we're using have been extracted for specific model domains as vertically integrated values of carbon in mols, in this case using 1 degree resolution across the model domain.

Here, we'll convert plankton carbon densities to total carbon, summed over the model domain. This is similar to, but an improvement upon, [Woodworth-Jefcoats et al. 2019](https://www.frontiersin.org/articles/10.3389/fmars.2019.00383/full).  

Here, this total carbon is used to create resource spectra at each monthly time step from Jan 1961 - Dec 2010.

To construct a plankton spectra, we need to assign size classes for each distinct phytoplankton and zooplankton product.

# FishMIP Data Explorer

https://0rl5bx-julia0blanchard.shinyapps.io/FishMIP_Input_Explorer/

# Extract your own data

Thanks to a great tutorial provided by Denisse Fierro Arcos, you can extract these same forcings for your own regions. All you need is a shapefile and you should be able to follow along.

https://github.com/Fish-MIP/FishMIP_NOAA_workshop

# Plankton Forcing

## Plankton size classes

Size class ranges, for reference (ESD = Equivalent Spherical Diameter):  
- Phyto = 0.2 - 200 um ESD (mid-point size = 100.1 um ESD)  
-	pico = 0.2 - 10 um ESD (mid-point size = 5.1 um ESD)  
-	large (diatoms and diazotrophs) = 10 - 200 um ESD (mid-point size = 105 um ESD)  
- Zoo = 2 - 20,000 um ESD (based on the literature)(mid-point size = 10001 um ESD)  
-	zmicro = 2 - 200 um ESD (mid-point size = 101 um ESD)  
-	zmeso = 200 - 20,000 um ESD (mid-point size = 10100 um ESD)  

These size classes were informed by Dunne et al. [2005](https://doi.org/10.1029/2004GB002390), [2012](https://doi.org/10.1029/2010GB003935), and [2013](https://doi.org/10.1175/JCLI-D-12-00150.1), [Liu et al. 2021](https://doi.org/10.1029/2021GL094367), and [Stock et al. 2020](https://doi.org/10.1029/2019MS002043).

## Conversions used:  

- Convert mol C to g C --> $\times 12.001$

- Convert g C to gww --> $\times 10$  

- Convert um ESD to gww --> $\frac{4}{3}\pi(0.5\times0.0001\times size)^3$

## Model domain

### Check model domain area

Need a file that has the area_m2 info.
```{r}
# Load total carbon data for picoplankton and reformat dataframe
df_diat_raw <- read.csv("Plankton_Forcings/gfdl-mom6-cobalt2_obsclim_phydiat-vint_60arcmin_Hawaiian-Longline_monthly_1961_2010.csv")
```


```{r}
df_area <- df_diat_raw %>% 
  select(area_m2)
  
Hawaiian_Longline_area <- df_diat_raw %>%
  select(c(lat,lon,area_m2)) %>%  
  mutate(total_area = sum(area_m2))

head(Hawaiian_Longline_area)
dim(Hawaiian_Longline_area)

dim(df_area)
summary(df_area)
```

Each 1 degree grid cell -->   $9540434011 m2$

Total model domain -->    $1.95e+13 m2$


# Prepare plankton forcings

Need to do diatoms first to extract area vector

## Diatoms
```{r}
# Load total carbon data for picoplankton and reformat dataframe
df_diat_raw <- read.csv("Plankton_Forcings/gfdl-mom6-cobalt2_obsclim_phydiat-vint_60arcmin_Hawaiian-Longline_monthly_1961_2010.csv")

dim(df_diat_raw)
# glimpse(df_diat_raw)
# head(df_diat_raw)
```


```{r}
df_diat_long <- df_diat_raw %>%
  gather(Date, mol_C_m2,Jan_1961:Dec_2010) %>% # Convert from wide format to long
  mutate(C_g_m2 = mol_C_m2 * 12.001) %>% # Convert from mol C m^2 to g C m^2
  mutate(C_g = mol_C_m2*area_m2) %>% # g C per grid cell by multiplying by area in m^2 per grid cell
  mutate(C_gww = C_g * 10) %>% # *10 to get grams wet weight
  mutate(date = parse_date_time(Date, orders = "my"))

df_area <- df_diat_long$area_m2
df_date <- df_diat_long$date

df_diat_long <- df_diat_long %>% # Create a tidy date variable
  group_by(date) %>% # group by month
  summarise(total_C_gww = sum(C_gww)) # sum carbon so it is total carbon for whole model domain per month

head(df_diat_long)
dim(df_diat_long)
```

## Picoplankton

```{r}
# Load total carbon data for picoplankton and reformat dataframe
df_pico_raw <- read.csv("Plankton_Forcings/gfdl-mom6-cobalt2_obsclim_phypico-vint_60arcmin_Hawaiian-Longline_monthly_1961_2010.csv")

dim(df_pico_raw)
# glimpse(df_pico_raw)
# head(df_pico_raw)
```


```{r}
# df_pico_long <- df_pico_raw %>%
#   select(!c(lat,lon)) %>% # remove lat, lon
#   melt() %>% # melt data from a wide array to long format
#   mutate(C_g_m2 = value * 12.001) %>% # Convert from mol C m^2 to g C m^2
#   mutate(C_g = C_g_m2*9540434011) %>% # Calculate total g C per grid cell by multiplying by area in m^2 per grid cell
#   group_by(variable) %>% # group by month
#   summarise(total_C_g = sum(C_g)) %>%  # sum carbon so it is total carbon for whole model domain per month
#   mutate(date = seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months")) %>% # create a tidy date variable
#   select(date, total_C_g) # select final variables
  

df_pico_long <- df_pico_raw %>%
  gather(Date, mol_C_m2, X1961.01.01.00.00.00:X2010.12.01.00.00.00) %>% # Convert from wide format to long
  mutate(area_m2 = df_area) %>% 
  mutate(date = df_date) %>% 
  mutate(C_g_m2 = mol_C_m2 * 12.001) %>% # Convert from mol C m^2 to g C m^2
  mutate(C_g = mol_C_m2*area_m2) %>% # g C per grid cell by multiplying by area in m^2 per grid cell
  mutate(C_gww = C_g * 10) %>% # *10 to get grams wet weight
  # mutate(date = parse_date_time(Date, orders = "my")) %>% # Create a tidy date variable
  group_by(date) %>% # group by month
  summarise(total_C_gww = sum(C_gww)) # sum carbon so it is total carbon for whole model domain per month
```


*Important*
Need to update so the area is used grid cell by grid cell

```{r}
# df_diat_long <- df_diat_raw %>%
#   select(!c(lat,lon,area_m2)) %>% # remove lat, lon, area_m2
#   melt() %>% # melt data from a wide array to long format
#   mutate(C_g_m2 = value * 12.001) %>% # Convert from mol C m^2 to g C m^2
#   mutate(C_g = C_g_m2*9540434011) %>% # Calculate total g C per grid cell by multiplying by area in m^2 per grid cell
#   group_by(variable) %>% # group by month
#   summarise(total_C_g = sum(C_g)) %>%  # sum carbon so it is total carbon for whole model domain per month
#   mutate(date = seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months")) %>% # create a tidy date variable
#   select(date, total_C_g) # select final variables
# 
# dim(df_diat_long)
# head(df_diat_long)
```

## Diazotrophs
```{r}
# Load total carbon data for picoplankton and reformat dataframe
df_diaz_raw <- read.csv("Plankton_Forcings/gfdl-mom6-cobalt2_obsclim_phydiaz-vint_60arcmin_Hawaiian-Longline_monthly_1961_2010.csv")

dim(df_diaz_raw)
# glimpse(df_diaz_raw)
# head(df_diaz_raw)
```

```{r}
# df_diaz_long <- df_diaz_raw %>%
#   select(!c(lat,lon)) %>% # remove lat, lon
#   melt() %>% # melt data from a wide array to long format
#   mutate(C_g_m2 = value * 12.001) %>% # Convert from mol C m^2 to g C m^2
#   mutate(C_g = C_g_m2*9540434011) %>% # Calculate total g C per grid cell by multiplying by area in m^2 per grid cell
#   group_by(variable) %>% # group by month
#   summarise(total_C_g = sum(C_g)) %>%  # sum carbon so it is total carbon for whole model domain per month
#   mutate(date = seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months")) %>% # create a tidy date variable
#   select(date, total_C_g) # select final variables

df_diaz_long <- df_diaz_raw %>%
  gather(Date, mol_C_m2, X1961.01.01.00.00.00:X2010.12.01.00.00.00) %>% # Convert from wide format to long
  mutate(area_m2 = df_area) %>% 
  mutate(date = df_date) %>% 
  mutate(C_g_m2 = mol_C_m2 * 12.001) %>% # Convert from mol C m^2 to g C m^2
  mutate(C_g = mol_C_m2*area_m2) %>% # g C per grid cell by multiplying by area in m^2 per grid cell
  mutate(C_gww = C_g * 10) %>% # *10 to get grams wet weight
  # mutate(date = parse_date_time(Date, orders = "my")) %>% # Create a tidy date variable
  group_by(date) %>% # group by month
  summarise(total_C_gww = sum(C_gww)) # sum carbon so it is total carbon for whole model domain per month
```

## Microzooplankton
```{r}
# Load total carbon data for picoplankton and reformat dataframe
df_zmicro_raw <- read.csv("Plankton_Forcings/gfdl-mom6-cobalt2_obsclim_zmicro-vint_60arcmin_Hawaiian-Longline_monthly_1961_2010.csv")

dim(df_zmicro_raw)
# glimpse(df_zmicro_raw)
# head(df_zmicro_raw)
```

```{r}
# df_zmicro_long <- df_zmicro_raw %>%
#   select(!c(lat,lon, area_m2)) %>% # remove lat, lon, area_m2
#   melt() %>% # melt data from a wide array to long format
#   mutate(C_g_m2 = value * 12.001) %>% # Convert from mol C m^2 to g C m^2
#   mutate(C_g = C_g_m2*9540434011) %>% # Calculate total g C per grid cell by multiplying by area in m^2 per grid cell
#   group_by(variable) %>% # group by month
#   summarise(total_C_g = sum(C_g)) %>%  # sum carbon so it is total carbon for whole model domain per month
#   mutate(date = seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months")) %>% # create a tidy date variable
#   select(date, total_C_g) # select final variables

df_zmicro_long <- df_zmicro_raw %>%
  gather(Date, mol_C_m2,Jan_1961:Dec_2010) %>% # Convert from wide format to long
  mutate(C_g_m2 = mol_C_m2 * 12.001) %>% # Convert from mol C m^2 to g C m^2
  mutate(C_g = mol_C_m2*area_m2) %>% # g C per grid cell by multiplying by area in m^2 per grid cell
  mutate(C_gww = C_g * 10) %>% # *10 to get grams wet weight
  mutate(date = parse_date_time(Date, orders = "my")) %>% # Create a tidy date variable
  group_by(date) %>% # group by month
  summarise(total_C_gww = sum(C_gww)) # sum carbon so it is total carbon for whole model domain per month
```

## Mesozooplankton
```{r}
# Load total carbon data for picoplankton and reformat dataframe
df_zmeso_raw <- read.csv("Plankton_Forcings/gfdl-mom6-cobalt2_obsclim_zmeso-vint_60arcmin_Hawaiian-Longline_monthly_1961_2010.csv")

dim(df_zmeso_raw)
# glimpse(df_zmeso_raw)
# head(df_zmeso_raw)
```


```{r}
# df_zmeso_long <- df_zmeso_raw %>%
#   select(!c(lat,lon, area_m2)) %>% # remove lat, lon, area_m2
#   melt() %>% # melt data from a wide array to long format
#   mutate(C_g_m2 = value * 12.001) %>% # Convert from mol C m^2 to g C m^2
#   mutate(C_g = C_g_m2*9540434011) %>% # Calculate total g C per grid cell by multiplying by area in m^2 per grid cell
#   group_by(variable) %>% # group by month
#   summarise(total_C_g = sum(C_g)) %>%  # sum carbon so it is total carbon for whole model domain per month
#   mutate(date = seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months")) %>% # create a tidy date variable
#   select(date, total_C_g) # select final variables

df_zmeso_long <- df_zmeso_raw %>%
  gather(Date, mol_C_m2,Jan_1961:Dec_2010) %>% # Convert from wide format to long
  mutate(C_g_m2 = mol_C_m2 * 12.001) %>% # Convert from mol C m^2 to g C m^2
  mutate(C_g = mol_C_m2*area_m2) %>% # g C per grid cell by multiplying by area in m^2 per grid cell
  mutate(C_gww = C_g * 10) %>% # *10 to get grams wet weight
  mutate(date = parse_date_time(Date, orders = "my")) %>% # Create a tidy date variable
  group_by(date) %>% # group by month
  summarise(total_C_gww = sum(C_gww)) # sum carbon so it is total carbon for whole model domain per month
```



## Create size mid points in grams wet weight (gww)

```{r}
# Create variables for referencing the size class mid points, in gww
pico_mid <- (4/3)*pi*((0.5*0.0001*5.1)^3)
large_mid <- (4/3)*pi*((0.5*0.0001*105)^3)
micro_mid <- (4/3)*pi*((0.5*0.0001*101)^3)
meso_mid <- (4/3)*pi*((0.5*0.0001*10100)^3)
```

## Convert to gww and then abundance

```{r}
# Get numerical abundance by dividing by size class mid point
# This step assumes that all plankton are the midpoint size
pico_abund <- df_pico_long[,2]/pico_mid
large_abund <- (df_diat_long[,2] + df_diaz_long[,2])/large_mid
micro_abund <- df_zmicro_long[,2]/micro_mid
meso_abund <- df_zmeso_long[,2]/meso_mid

# Combine mid-point sizes for generating the x-axis for the linear fit
plankton_x <- log10(c(pico_mid, micro_mid, large_mid, meso_mid))

# The full spectrum sizes were generated by setting up a mizer params:
```

## Load mizer

```{r}
library(mizer)
# params <- newMultispeciesParams(mizer::NS_params@species_params, min_w_pp = 1e-14)
```

## Create model params

We need this to get the full size spectrum from the model

```{r}
# The full spectrum sizes were generated by setting up a mizer params:
HIparams <- read.csv("HIregion_species_params.csv")
HIinter <- read.csv("HIregion_inter.csv")[,-1]
rownames(HIinter) <- colnames(HIinter)

params <- newMultispeciesParams(HIparams, interaction = HIinter, kappa = 1e12, min_w_pp = 1e-14)

# and accessing the full size range
full_x <- log10(params@w_full)

length(full_x)
```


## Create background resource

```{r}
# Creating background resource for full_x, using the actual slope and intercept from the linear models.
# Create array and fill it
out_isimip <- array(numeric(), c(600,226)) # 600 time steps by 226 size classes
isimip_slope <- array(numeric(), c(600,1)) # 600 time steps
isimip_intercept <- array(numeric(), c(600,1)) # 600 time steps



# y values
for (t in seq(1,600,1)) {
	isimip_plankton <- log10(c(pico_abund$total_C_g[t], micro_abund$total_C_g[t], large_abund$total_C_g[t], meso_abund$total_C_g[t]))
		
	# Calculate slope and intercept, expand spectra for full size range
	# Linear fits
	isimip_lm <- lm(isimip_plankton ~ plankton_x)
	
	# Expand to full size range
	# out_isimip[t,] <- isimip_lm$coefficients[2] * full_x + isimip_lm$coefficients[1]
	out_isimip[t,] <- isimip_lm$coefficients[2]*1.03 * full_x + isimip_lm$coefficients[1]*0.85
	# The scaling for the slope and intercept were determined following the method in 
	# Woodworth-Jefcoats et al. (2019)  More information is provided below.
	
	# Save slope and intercept, for diagnostics
	isimip_intercept[t,1] <- isimip_lm$coefficients[1]
	isimip_slope[t,1] <- isimip_lm$coefficients[2]
	
}
```

## Plot full spectrum

```{r}
ggplot(,aes(x = full_x, y = out_isimip[1,])) +
  geom_point() +
  # geom_line() +
  # geom_smooth() +
  scale_y_log10() +
  xlab("Size (log10 g)") +
  ylab("Abundance (log10)") +
  theme_bw()
```

## Intercept timeseries 

```{r}
months <- seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months") # create a tidy date variable

ggplot(,aes(x = months, y = isimip_intercept[,1])) +
  geom_point() +
  geom_line() +
  geom_smooth() +
  xlab("Year") +
  ylab("log10 Intercept") +
  theme_bw()
```

## Slope timeseries

```{r}
ggplot(,aes(x = months, y = isimip_slope[,1])) +
  geom_point() +
  geom_line() +
  geom_smooth() +
  xlab("Year") +
  ylab("Background Resource Slope") +
  theme_bw()
```

## Save files

```{r}
# Save
write.table(out_isimip, file = "GFDL_resource_spectra_60arcmin.dat", quote = FALSE, row.names = TRUE, col.names = TRUE)
write.table(isimip_slope, file = "GFDL_resource_slope_60arcmin.dat", quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)
write.table(isimip_intercept, file = "GFDL_resource_intercept_60arcmin.dat", quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)

```

### Phoebe's notes from each scaling iteration  
Because of differences across earth system models (ESMs), I've thus far found it necessary to scale the ESM output in order to obtain a realistic mizer model.  To do this, I run therMizer with all the species parameters and no plankton forcing.  I look at the resulting resource generated by the semi-chemostat model as a reference.  I also look at the behavior of the feeding level (FL) across species and sizes.  Then, I scale the slope and intercept iteratively, optimizing the feeding level to match that generated without plankton forcing.  I also compare modeled and observed catch, too (not shown here - see FishingForcing).  This is admittedly tedious...

When multiple ESMs are used in the same simulation round or same study, the same scaling is applied to all ESMs.

Slope and intercept unscaled: FL = 1 all species and sizes  
Slope $\times$ 1.1 and intercept $\times$ 0.9: FL decreasing slightly with increasing size, still high (0.8 - 1)  
Slope $\times$ 1.2 and intercept $\times$ 0.8: FL declines strongly with increasing size, 0.4 - 0.8 for small sizes 0 - 0.2 for large sizes.  
Slope $\times$ 1.1 and intercept $\times$ 0.8: very similar to previous scaling (S1.2I0.2).  
Slope $\times$ 1.2 and intercept $\times$ 0.9: similar to S1.1I0.9, but decreasing more with size  
Slope unscaled and intercept $\times$ 0.8: FL low (0.1 sm - 0.5 lg) and increases with body size  
Slope unscaled and intercept $\times$ 0.9: FL high (0.6 - 0.9 sm to 0.75 - 1 large) and increases with body size  
Slope unscaled and intercept $\times$ 0.85: FL look good, albeit a bit spread across species, still increasing with increasing body size  
Slope $\times$ 1.1 and intercept $\times$ 0.85: Closer.  FL good at larger sizes, decreasing with body size  
Slope $\times$ 1.05 and intercept $\times$ 0.85: Even closer.  FL decreasing less with body size.  
Slope $\times$ 1.05 and intercept $\times$ 0.9: FL high, but more consistent across body sizes  
Slope $\times$ 1.025 and intercept $\times$ 0.85: FL good, increasing slightly with body size  
Slope $\times$ 1.03 and intercept $\times$ 0.85: Going with this option.  FL in the same range as base run and similarly flat across body sizes.  

Finally, an equally valid approach would be to save the resource spectra generated by the semi-chemostat model and to scale those spectra slopes and intercepts using the change in slope and intercept generated from the ESM at each time step (rather than scaling the ESM output).  You'd probably want to do this by comparing each time step to a baseline period, as is done with temperature.



# Temperature Forcing

This an example of how you would prepare temperature forcings, using the 2D surface temperature (tos) and bottom temperature (tob), but in the model run script, Phoebe has already prepared a depth resolved temperature array for the forcing, so we're going to use that in `Hawaii_Longline_Simplified_Model_Runs.Rmd`

```{r}
# Load surface temperature data
df_gfdl_tos <- read.csv("Temperature_Forcings/gfdl-mom6-cobalt2_obsclim_tos_60arcmin_hawaiian-longline_monthly_1961_2010.csv") 

df_gfdl_tob <- read.csv("Temperature_Forcings/gfdl-mom6-cobalt2_obsclim_tob_60arcmin_hawaiian-longline_monthly_1961_2010.csv") 

# head(df_gfdl_tos)
# head(df_gfdl_tob)

summary(df_gfdl_tos$lat)
summary(df_gfdl_tos$lon)

summary(df_gfdl_tob$lat)
summary(df_gfdl_tob$lon)

```



If you need to perform a correction for your region, the World Ocean Atlas is an example of a database you can get temperature data from

World Ocean Atlas data
https://www.ncei.noaa.gov/access/world-ocean-atlas-2023/bin/woa23.pl

For a details on how this temperature correction can be performed, see `Prep_TempRealms_therMizer.Rmd` in therMizer-FishMIP-2022-HI > ClimateForcing > Temperature

## Tidy surface temperature

```{r}
GFDL_tos <- df_gfdl_tos %>%
  select(!c(lat,lon,area_m2)) %>% # remove lat, lon and area_m2
  melt() %>% # surface temperature of each area for all grid cells
  group_by(variable) %>% # group by month
  rename(date = variable) %>%  # rename variable to something meaningful
  summarise(tos = mean(value)) %>% # mean temperature across all grid cells in model region for each month
  mutate(date_tidy = parse_date_time(date, orders = "my")) %>% 
  select(date_tidy, tos)

glimpse(GFDL_tos)
head(GFDL_tos)
```

## Tidy bottom temperature

```{r}
GFDL_tob <- df_gfdl_tob %>%
  select(!c(lat,lon,area_m2)) %>% # remove lat, lon and area_m2
  melt() %>% # surface temperature of each area for all grid cells
  group_by(variable) %>% # group by month
  rename(date = variable) %>%  # rename variable to something meaningful
  summarise(tob = mean(value)) %>%  # mean temperature across all grid cells in model region for each month
  mutate(date_tidy = parse_date_time(date, orders = "my")) %>% 
  select(date_tidy, tob)

glimpse(GFDL_tob)
head(GFDL_tob)
```

To get a crude representation of temperature gradient in the water column, assume (or calculate if you have bathymetry) that the Sea Water Potential Temperature at Sea Floor `tob` is a mean depth of 2000m, then let's create values of temperature throughout the water column based on the difference between the surface temperature, `tos` and `tob`

But of course, you'd be better of getting your hands on the 3D sea water potential temperature file, thetao and using this.

## Incorporate depth (poorly)

```{r}
df_temp_water_column <- left_join(GFDL_tos, GFDL_tob) %>% 
  mutate(t500m = (tob - tos)/4 + tos,
         t1000m = (tob - tos)/2 + tos,
         t1500m = ((tob - tos)/4)*3 + tos) %>% 
  select(date_tidy, tos, t500m, t1000m, t1500m, tob)

glimpse(df_temp_water_column)
head(df_temp_water_column)
```

## Check the temperature trends

```{r}
df_temp_water_column %>% 
  ggplot(aes(x = date_tidy, y = tob), colour = "black") +
  xlab("Year") +
  ylab("Temperature (°C)") +
  geom_line(aes(x = date_tidy, y = tos), colour = "grey") +
  geom_smooth(aes(x = date_tidy, y = tos, alpha = 0.001), colour = "grey") +
  geom_smooth(aes(x = date_tidy, y = t500m, alpha = 0.0001), colour = "red") +
  geom_smooth(aes(x = date_tidy, y = t1000m, alpha = 0.0001), colour = "orange") +
  geom_smooth(aes(x = date_tidy, y = t1500m, alpha = 0.0001), colour = "cyan") +
  geom_line() + 
  geom_smooth(colour = "black") +
  theme_classic() +
  theme(legend.position = "none")     
```

## Plot tos 

```{r}
df_temp_water_column %>% 
  ggplot(aes(x = date_tidy, y = tos), colour = "black") +
  xlab("Year") +
  ylab("Temperature (°C)") +
  geom_line() + 
  geom_smooth(colour = "black") +
  theme_classic() +
  ggtitle("Surface Temperature") +
  theme(legend.position = "none") 
```


## Plot tob

```{r}
df_temp_water_column %>% 
  ggplot(aes(x = date_tidy, y = tob), colour = "black") +
  xlab("Year") +
  ylab("Temperature (°C)") +
  geom_line() + 
  geom_smooth(colour = "black") +
  theme_classic() +
  ggtitle("Bottom Temperature") +
  theme(legend.position = "none") 
```


## Save in a format that will be therMizer-friendly

```{r}
tos <- df_temp_water_column$tos
names(tos) <- seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months")
saveRDS(tos, file = "Temperature_Forcings/tos.rds")

t500m <- df_temp_water_column$t500m
names(t500m) <- seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months")
saveRDS(t500m, file = "Temperature_Forcings/t500m.rds")

t1000m <- df_temp_water_column$t1000m
names(t1000m) <- seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months")
saveRDS(t1000m, file = "Temperature_Forcings/t1000m.rds")

t1500m <- df_temp_water_column$t1500m
names(t1500m) <- seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months")
saveRDS(t1500m, file = "Temperature_Forcings/t1500m.rds")

tob <- df_temp_water_column$tob
names(tob) <- seq(as.Date("1961-01-01"),as.Date("2010-12-01"),by="months")
saveRDS(tob, file = "Temperature_Forcings/tob.rds")

```








